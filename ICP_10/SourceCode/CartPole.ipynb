{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CartPole.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ukp9ry-mEM0i"
      },
      "source": [
        "Let's install some libraries for visualization.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4TGabNT3GJ9",
        "outputId": "3c887fe3-75cd-46ad-c610-5ca9b0a61cec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!apt-get install python-opengl -y\n",
        "!apt install xvfb -y\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install piglet"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  libgle3\n",
            "The following NEW packages will be installed:\n",
            "  python-opengl\n",
            "0 upgraded, 1 newly installed, 0 to remove and 11 not upgraded.\n",
            "Need to get 496 kB of archives.\n",
            "After this operation, 5,416 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n",
            "Fetched 496 kB in 1s (436 kB/s)\n",
            "Selecting previously unselected package python-opengl.\n",
            "(Reading database ... 144628 files and directories currently installed.)\n",
            "Preparing to unpack .../python-opengl_3.1.0+dfsg-1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-1) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 11 not upgraded.\n",
            "Need to get 783 kB of archives.\n",
            "After this operation, 2,266 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.7 [783 kB]\n",
            "Fetched 783 kB in 1s (654 kB/s)\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 146983 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.7_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.7) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.7) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading https://files.pythonhosted.org/packages/d0/8a/643043cc70791367bee2d19eb20e00ed1a246ac48e5dbe57bbbcc8be40a9/PyVirtualDisplay-1.3.2-py2.py3-none-any.whl\n",
            "Collecting EasyProcess\n",
            "  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n",
            "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
            "Successfully installed EasyProcess-0.3 pyvirtualdisplay-1.3.2\n",
            "Collecting piglet\n",
            "  Downloading https://files.pythonhosted.org/packages/11/56/6840e5f45626dc7eb7cd5dff57d11880b3113723b3b7b1fb1fa537855b75/piglet-1.0.0-py2.py3-none-any.whl\n",
            "Collecting piglet-templates\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/dc/d628dcdf0b38b8f230e9c2309bfa370d2e3fb95e9e9c260213d10fde91ac/piglet_templates-1.0.0-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from piglet-templates->piglet) (20.2.0)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.6/dist-packages (from piglet-templates->piglet) (1.6.3)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.6/dist-packages (from piglet-templates->piglet) (1.1.1)\n",
            "Collecting Parsley\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/d6/4fed8d65e28a970e1c5cb33ce9c7e22e3de745e1b2ae37af051ef16aea3b/Parsley-1.3-py2.py3-none-any.whl (88kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from astunparse->piglet-templates->piglet) (0.35.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from astunparse->piglet-templates->piglet) (1.15.0)\n",
            "Installing collected packages: Parsley, piglet-templates, piglet\n",
            "Successfully installed Parsley-1.3 piglet-1.0.0 piglet-templates-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYhrQq7WEmYr"
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "Display().start()\n",
        "\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import random\n",
        "import gym\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXt_cPU5CkIo"
      },
      "source": [
        "class DQNAgent:\n",
        "    def __init__(self, state_size, action_size):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.memory = deque(maxlen=2000)\n",
        "\n",
        "        # hyperparameters\n",
        "        self.gamma = 0.95    # discount rate\n",
        "        self.epsilon = 1.0  # exploration rate\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.995\n",
        "        self.learning_rate = 0.001\n",
        "        self.model = self._build_model()\n",
        "\n",
        "    def _build_model(self):\n",
        "        # Neural Net for Deep-Q learning Model\n",
        "        model = Sequential()\n",
        "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
        "        model.add(Dense(24, activation='relu'))\n",
        "        model.add(Dense(self.action_size, activation='linear'))\n",
        "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
        "        return model\n",
        "\n",
        "    def memorize(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "        act_values = self.model.predict(state)\n",
        "        return np.argmax(act_values[0])  # returns action\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        minibatch = random.sample(self.memory, batch_size)\n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "            target = reward\n",
        "            if not done:\n",
        "                target = (reward + self.gamma *\n",
        "                          np.amax(self.model.predict(next_state)[0]))\n",
        "            target_f = self.model.predict(state)\n",
        "            target_f[0][action] = target\n",
        "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def load(self, name):\n",
        "        self.model.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.model.save_weights(name)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZot47aCCoTG",
        "outputId": "3b7e4dd7-f280-44e3-bee2-1c5456447a28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # creating the environment for Cart Pole\n",
        "    env = gym.make('CartPole-v1')\n",
        "    \n",
        "    # reseting the environment so that it returns the initial state\n",
        "    state = env.reset()\n",
        "\n",
        "    # img = plt.imshow(env.render('rgb_array')) # only call this once\n",
        "    # episode_dict = {}\n",
        "\n",
        "    # board is an 2x2 matrix which is used for saving the states for plotting \n",
        "    board = []\n",
        "\n",
        "    #  There are 4 states for the CartPole  [position of cart, velocity of cart, angle of pole, rotation rate of pole]\n",
        "    state_size = env.observation_space.shape[0]\n",
        "\n",
        "    # There are 2 actions available  [0:Push cart to the left, 1:\tPush cart to the right]\n",
        "    action_size = env.action_space.n\n",
        "\n",
        "    # create an agent instance \n",
        "    agent = DQNAgent(state_size, action_size)\n",
        "\n",
        "    # game is not over so that done is set to False\n",
        "    done = False\n",
        "    # batch_size is for training neural network.\n",
        "    batch_size = 10\n",
        "\n",
        "\n",
        "    # Number of games to play\n",
        "    EPISODES = 60\n",
        "\n",
        "    for e in range(EPISODES):\n",
        "        state = env.reset()\n",
        "        state = np.reshape(state, [1, state_size])\n",
        "\n",
        "        board.append([])\n",
        "\n",
        "        # maximum score is 500. \n",
        "        for time in range(500):\n",
        "        \n",
        "            # saving  each try in each episode to a 2d array. We will use it for visualization later.\n",
        "            board[e].append(env.render('rgb_array'))\n",
        "\n",
        "            #  Perform the action. Either 0 to left ot 1 to right.\n",
        "            action = agent.act(state)\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "            # check the new state and update the reward\n",
        "            reward = reward if not done else -10\n",
        "            next_state = np.reshape(next_state, [1, state_size])\n",
        "\n",
        "            # Save the previous episodes to use them for training later.\n",
        "            agent.memorize(state, action, reward, next_state, done)\n",
        "            state = next_state\n",
        "\n",
        "            # If we loose the game in the episode, it reports\n",
        "            if done:\n",
        "                print(\"episode: {}/{}, score: {}, e: {:.2}\"\n",
        "                      .format(e, EPISODES, time, agent.epsilon))\n",
        "                break\n",
        "\n",
        "            # If there are enough samples in the memory, use them for training\n",
        "            if len(agent.memory) > batch_size:\n",
        "                agent.replay(batch_size)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "episode: 0/60, score: 25, e: 0.93\n",
            "episode: 1/60, score: 19, e: 0.84\n",
            "episode: 2/60, score: 13, e: 0.79\n",
            "episode: 3/60, score: 17, e: 0.73\n",
            "episode: 4/60, score: 9, e: 0.69\n",
            "episode: 5/60, score: 10, e: 0.66\n",
            "episode: 6/60, score: 12, e: 0.62\n",
            "episode: 7/60, score: 14, e: 0.58\n",
            "episode: 8/60, score: 11, e: 0.55\n",
            "episode: 9/60, score: 9, e: 0.52\n",
            "episode: 10/60, score: 13, e: 0.49\n",
            "episode: 11/60, score: 12, e: 0.46\n",
            "episode: 12/60, score: 8, e: 0.44\n",
            "episode: 13/60, score: 13, e: 0.42\n",
            "episode: 14/60, score: 8, e: 0.4\n",
            "episode: 15/60, score: 14, e: 0.37\n",
            "episode: 16/60, score: 19, e: 0.34\n",
            "episode: 17/60, score: 10, e: 0.32\n",
            "episode: 18/60, score: 8, e: 0.31\n",
            "episode: 19/60, score: 10, e: 0.29\n",
            "episode: 20/60, score: 8, e: 0.28\n",
            "episode: 21/60, score: 8, e: 0.27\n",
            "episode: 22/60, score: 8, e: 0.26\n",
            "episode: 23/60, score: 10, e: 0.25\n",
            "episode: 24/60, score: 11, e: 0.23\n",
            "episode: 25/60, score: 11, e: 0.22\n",
            "episode: 26/60, score: 12, e: 0.21\n",
            "episode: 27/60, score: 9, e: 0.2\n",
            "episode: 28/60, score: 10, e: 0.19\n",
            "episode: 29/60, score: 8, e: 0.18\n",
            "episode: 30/60, score: 8, e: 0.18\n",
            "episode: 31/60, score: 10, e: 0.17\n",
            "episode: 32/60, score: 13, e: 0.16\n",
            "episode: 33/60, score: 11, e: 0.15\n",
            "episode: 34/60, score: 11, e: 0.14\n",
            "episode: 35/60, score: 9, e: 0.13\n",
            "episode: 36/60, score: 9, e: 0.13\n",
            "episode: 37/60, score: 12, e: 0.12\n",
            "episode: 38/60, score: 13, e: 0.11\n",
            "episode: 39/60, score: 13, e: 0.11\n",
            "episode: 40/60, score: 9, e: 0.1\n",
            "episode: 41/60, score: 9, e: 0.097\n",
            "episode: 42/60, score: 11, e: 0.092\n",
            "episode: 43/60, score: 8, e: 0.088\n",
            "episode: 44/60, score: 8, e: 0.084\n",
            "episode: 45/60, score: 8, e: 0.081\n",
            "episode: 46/60, score: 15, e: 0.075\n",
            "episode: 47/60, score: 20, e: 0.068\n",
            "episode: 48/60, score: 37, e: 0.057\n",
            "episode: 49/60, score: 64, e: 0.041\n",
            "episode: 50/60, score: 12, e: 0.039\n",
            "episode: 51/60, score: 42, e: 0.031\n",
            "episode: 52/60, score: 44, e: 0.025\n",
            "episode: 53/60, score: 56, e: 0.019\n",
            "episode: 54/60, score: 23, e: 0.017\n",
            "episode: 55/60, score: 83, e: 0.011\n",
            "episode: 56/60, score: 17, e: 0.01\n",
            "episode: 57/60, score: 17, e: 0.01\n",
            "episode: 58/60, score: 33, e: 0.01\n",
            "episode: 59/60, score: 47, e: 0.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7sLhJw8QimW"
      },
      "source": [
        "def show_me_episode(episode_number):\n",
        "  img = plt.imshow(env.render('rgb_array')) # only call this once\n",
        "  for i in range(len(board[episode_number])):\n",
        "    fr = board[episode_number][i]\n",
        "    img.set_data(fr) # just update the data\n",
        "    display.display(plt.gcf())\n",
        "    display.clear_output(wait=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrXnFaqTytI5"
      },
      "source": [
        "# To see any specific episode\n",
        "show_me_episode(57)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PslvZiX2W4UF",
        "outputId": "e2d90477-d299-41c7-959c-026b9db9d86e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "for k in range(len(board)):\n",
        "  show_me_episode(k)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}